{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kasun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/kasun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[('good', 'JJ'), ('day', 'NN'), ('ladies', 'NNS'), ('and', 'CC'), ('gentleman', 'NN'), ('and', 'CC'), ('welcome', 'NN'), ('to', 'TO'), ('the', 'DT'), ('alphabet', 'JJ'), ('second', 'JJ'), ('quarter', 'NN'), ('2018', 'CD'), ('earnings', 'NNS'), ('call', 'NN'), ('at', 'IN'), ('this', 'DT'), ('time', 'NN'), ('all', 'DT'), ('participants', 'NNS'), ('are', 'VBP'), ('in', 'IN'), ('a', 'DT'), ('listen-only', 'JJ'), ('mode', 'NN'), ('later', 'RBR'), ('we', 'PRP'), ('will', 'MD'), ('conduct', 'VB'), ('question-and-answer', 'JJR'), ('session', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('given', 'VBN'), ('at', 'IN'), ('that', 'DT'), ('time', 'NN'), ('if', 'IN'), ('anyone', 'NN'), ('should', 'MD'), ('car', 'NN'), ('operator', 'NN'), ('assistance', 'NN'), ('to', 'TO'), ('spell', 'VB'), ('star', 'NN'), ('and', 'CC'), ('then', 'RB'), ('0', 'CD'), ('on', 'IN'), ('your', 'PRP$'), ('touch-tone', 'NN'), ('telephone', 'NN'), ('and', 'CC'), ('now', 'RB'), ('it', 'PRP'), (\"'\", \"''\"), ('s', 'NN'), ('in', 'IN'), ('the', 'DT'), ('conference', 'NN'), ('call', 'NN'), ('over', 'IN'), ('to', 'TO'), ('Ellen', 'NNP'), ('West', 'NNP'), ('had', 'VBD'), ('an', 'DT'), ('investor', 'NN'), ('relations', 'NNS'), ('please', 'VBP'), ('go', 'VB'), ('ahead', 'RB'), ('thank', 'NN'), ('you', 'PRP'), ('good', 'JJ'), ('afternoon', 'NN'), ('everyone', 'NN'), ('and', 'CC'), ('welcome', 'NN'), ('to', 'TO'), ('alphabet', 'VB'), ('second', 'JJ'), ('quarter', 'NN'), ('2018', 'CD'), ('earnings', 'NNS'), ('conference', 'NN'), ('call', 'NN'), ('with', 'IN'), ('us', 'PRP'), ('today', 'NN'), ('our', 'PRP$'), ('Ruth', 'NNP'), ('Pratt', 'NNP'), ('and', 'CC'), ('Sundar', 'NNP'), ('pichai', 'NN'), ('now', 'RB'), ('I', 'PRP'), (\"'\", \"''\"), ('ll', 'JJ'), ('quickly', 'RB'), ('cover', 'VB'), ('the', 'DT'), ('Safe', 'NNP'), ('Harbor', 'NNP'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), ('statements', 'NNS'), ('that', 'IN'), ('we', 'PRP'), ('make', 'VBP'), ('today', 'NN'), ('may', 'MD'), ('be', 'VB'), ('considered', 'VBN'), ('forward-looking', 'JJ'), ('including', 'VBG'), ('statements', 'NNS'), ('regarding', 'VBG'), ('our', 'PRP$'), ('future', 'NN'), ('Investments', 'NNS'), ('are', 'VBP'), ('long-term', 'JJ'), ('growth', 'NN'), ('and', 'CC'), ('Innovation', 'NNP'), ('the', 'DT'), ('expected', 'JJ'), ('performance', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('businesses', 'NNS')]\n",
      "good\n",
      "day\n",
      "ladi\n",
      "gentleman\n",
      "welcom\n",
      "alphabet\n",
      "second\n",
      "quarter\n",
      "earn\n",
      "call\n",
      "time\n",
      "particip\n",
      "listen-onli\n",
      "mode\n",
      "session\n",
      "time\n",
      "anyon\n",
      "car\n",
      "oper\n",
      "assist\n",
      "star\n",
      "touch-ton\n",
      "telephon\n",
      "confer\n",
      "call\n",
      "ellen\n",
      "west\n",
      "investor\n",
      "relat\n",
      "thank\n",
      "good\n",
      "afternoon\n",
      "everyon\n",
      "welcom\n",
      "second\n",
      "quarter\n",
      "earn\n",
      "confer\n",
      "call\n",
      "today\n",
      "ruth\n",
      "pratt\n",
      "sundar\n",
      "pichai\n",
      "safe\n",
      "harbor\n",
      "statement\n",
      "today\n",
      "statement\n",
      "futur\n",
      "invest\n",
      "long-term\n",
      "growth\n",
      "innov\n",
      "expect\n",
      "perform\n",
      "busi\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "text = \"\"\"good day ladies and gentleman and welcome to the alphabet second quarter 2018 earnings call\n",
    "at this time all participants are in a listen-only mode later we will conduct question-and-answer session\n",
    "and it will be given at that time if anyone should car operator assistance to spell star and then 0 on \n",
    "your touch-tone telephone and now it's in the conference call over to Ellen West had an investor relations\n",
    "please go ahead thank you good afternoon everyone and welcome to alphabet second quarter 2018 earnings \n",
    "conference call with us today our Ruth Pratt and Sundar pichai now I'll quickly cover the Safe Harbor \n",
    "some of the statements that we make today may be considered forward-looking including statements regarding\n",
    "our future Investments are long-term growth and Innovation the expected performance of our businesses\"\"\"\n",
    "\n",
    "# Used when tokenizing words\n",
    "sentence_re = r'''(?x)          # set flag to allow verbose regexps\n",
    "        (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "      | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "      | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "      | \\.\\.\\.              # ellipsis\n",
    "      | [][.,;\"'?():_`-]    # these are separate tokens; includes ], [\n",
    "    '''\n",
    "\n",
    "#sentence_re = r'(?:(?:[A-Z])(?:.[A-Z])+.?)|(?:\\w+(?:-\\w+)*)|(?:$?\\d+(?:.\\d+)?%?)|(?:...|)(?:[][.,;\"'?():-_`])'\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "#Taken from Su Nam Kim Paper...\n",
    "grammar = r\"\"\"\n",
    "    NBAR:\n",
    "        {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n",
    "        \n",
    "    NP:\n",
    "        {<NBAR>}\n",
    "        {<NBAR><IN><NBAR>}  # Above, connected with in/of/etc...\n",
    "\"\"\"\n",
    "chunker = nltk.RegexpParser(grammar)\n",
    "\n",
    "toks = nltk.regexp_tokenize(text, sentence_re)\n",
    "postoks = nltk.tag.pos_tag(toks)\n",
    "\n",
    "print(postoks)\n",
    "\n",
    "tree = chunker.parse(postoks)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.label()=='NP'):\n",
    "        yield subtree.leaves()\n",
    "\n",
    "def normalise(word):\n",
    "    \"\"\"Normalises words to lowercase and stems and lemmatizes it.\"\"\"\n",
    "    word = word.lower()\n",
    "    word = stemmer.stem(word)\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "    return word\n",
    "\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    accepted = bool(2 <= len(word) <= 40\n",
    "        and word.lower() not in stopwords)\n",
    "    return accepted\n",
    "\n",
    "\n",
    "def get_terms(tree):\n",
    "    for leaf in leaves(tree):\n",
    "        term = [ normalise(w) for w,t in leaf if acceptable_word(w) ]\n",
    "        yield term\n",
    "\n",
    "terms = get_terms(tree)\n",
    "\n",
    "for term in terms:\n",
    "    for word in term:\n",
    "        print(word),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
